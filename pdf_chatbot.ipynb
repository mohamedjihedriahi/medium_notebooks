{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JI8cRDxy9p1",
        "outputId": "c404fc20-6bd7-4d28-8333-dfdaf3cfbac2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.27.9-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m71.7/75.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.5/75.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (1.5.3)\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDF==1.19.0\n",
            "  Downloading PyMuPDF-1.19.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.3)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.23.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: PyMuPDF, tiktoken, openai\n",
            "Successfully installed PyMuPDF-1.19.0 openai-0.27.9 tiktoken-0.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai pandas tiktoken PyMuPDF==1.19.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "5g1Q5O0Xe0Q1",
        "outputId": "036e77a9-312c-4e38-dad0-6d06b5554fb3"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e353b1b2-ca05-4b7a-b473-5c2cbd9b07e6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e353b1b2-ca05-4b7a-b473-5c2cbd9b07e6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving For a reliable chatbot with LLMs without Langchain.pdf to For a reliable chatbot with LLMs without Langchain.pdf\n",
            "Detected PDF file: For a reliable chatbot with LLMs without Langchain.pdf\n",
            "The PDF file has 4 pages.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "import fitz  # PyMuPDF library for working with PDFs\n",
        "import re\n",
        "import pandas as pd\n",
        "# Upload a file\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Check if any PDF file was uploaded\n",
        "pdf_file = None\n",
        "for filename, content in uploaded.items():\n",
        "    if filename.lower().endswith('.pdf'):\n",
        "        pdf_file = content\n",
        "        print(f\"Detected PDF file: {filename}\")\n",
        "        break\n",
        "\n",
        "if pdf_file :\n",
        "    with fitz.open(stream=pdf_file, filetype=\"pdf\") as pdf:\n",
        "        # Your code to work with the PDF using fitz\n",
        "        num_pages = len(pdf)\n",
        "        print(f\"The PDF file has {num_pages} pages.\")\n",
        "        text = []\n",
        "        for i,page in enumerate(pdf):\n",
        "            page_text = page.get_text()\n",
        "            clean_page_text = re.sub(\"\\n\", \" \", page_text)\n",
        "            text.append(clean_page_text)\n",
        "    df = pd.DataFrame({'text': text})\n",
        "else:\n",
        "    print(\"No PDF file was detected.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "blE4FaNinfjU",
        "outputId": "fcbfc833-cf0d-4240-cf98-da68fde46dc0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text\n",
              "0  For a reliable chatbot with LLMs without Langc...\n",
              "1  solution for various applications. You can bui...\n",
              "2  In a nutshell, here is, the overall structure:...\n",
              "3  Summary: how easily we could built reliable ch..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c7fd7ae0-5a51-4db0-9640-7d142954504b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>For a reliable chatbot with LLMs without Langc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>solution for various applications. You can bui...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In a nutshell, here is, the overall structure:...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Summary: how easily we could built reliable ch...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7fd7ae0-5a51-4db0-9640-7d142954504b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c7fd7ae0-5a51-4db0-9640-7d142954504b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c7fd7ae0-5a51-4db0-9640-7d142954504b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Txk6N5XnzBcx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"Your_OpenAI_api_key\"\n",
        "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
        "from openai.embeddings_utils import get_embedding, cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5j19TSRFzEol"
      },
      "outputs": [],
      "source": [
        "df[\"embeddings\"] = df.text.apply(lambda x: get_embedding(x, engine=\"text-embedding-ada-002\", api_key=openai.api_key))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "FEB64BP-zS84",
        "outputId": "3deb9f12-c759-4a72-b653-66e7217ef1b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  \\\n",
              "0  For a reliable chatbot with LLMs without Langc...   \n",
              "1  solution for various applications. You can bui...   \n",
              "2  In a nutshell, here is, the overall structure:...   \n",
              "3  Summary: how easily we could built reliable ch...   \n",
              "\n",
              "                                          embeddings  \n",
              "0  [0.0030642820056527853, 0.009529385715723038, ...  \n",
              "1  [-0.010922371409833431, 0.0016442183405160904,...  \n",
              "2  [-0.01927325688302517, 0.011952994391322136, 0...  \n",
              "3  [-0.010202204808592796, -0.010167385451495647,...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-be4c5bf7-7eed-4206-a2fe-f82c39c135fa\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>embeddings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>For a reliable chatbot with LLMs without Langc...</td>\n",
              "      <td>[0.0030642820056527853, 0.009529385715723038, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>solution for various applications. You can bui...</td>\n",
              "      <td>[-0.010922371409833431, 0.0016442183405160904,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In a nutshell, here is, the overall structure:...</td>\n",
              "      <td>[-0.01927325688302517, 0.011952994391322136, 0...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Summary: how easily we could built reliable ch...</td>\n",
              "      <td>[-0.010202204808592796, -0.010167385451495647,...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be4c5bf7-7eed-4206-a2fe-f82c39c135fa')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-be4c5bf7-7eed-4206-a2fe-f82c39c135fa button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-be4c5bf7-7eed-4206-a2fe-f82c39c135fa');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "zHVnD05L0R7N"
      },
      "outputs": [],
      "source": [
        "history=[]\n",
        "def update_chat(history, role, content):\n",
        "  history.append({\"role\": role, \"content\": content})\n",
        "  return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "hpf3VO7yWuU3"
      },
      "outputs": [],
      "source": [
        "def get_context(user_input):\n",
        "    # get user_input_vector\n",
        "    user_input_vector = get_embedding(user_input, engine=\"text-embedding-ada-002\", api_key=openai.api_key)\n",
        "    similarities = df['embeddings'].apply(lambda x: cosine_similarity(x, user_input_vector))\n",
        "    # Find the index of the row with the maximum similarity value\n",
        "    max_similarity_index = similarities.idxmax()\n",
        "    # Get the corresponding text content from the 'text' column\n",
        "    context = df.iloc[max_similarity_index][\"text\"]\n",
        "\n",
        "    return context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_n01dGLx1cqk",
        "outputId": "5a958dc7-2060-47af-9962-8796adbf6684"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Type 'exit' to exit the program.\n",
            "hello\n",
            "Bonjour ! Comment puis-je vous aider aujourd'hui ?qui etes vous ?\n",
            "Je suis un assistant de X company. Je peux vous aider à discuter avec votre document téléchargé et vous assister avec celui-ci. Avez-vous des questions concernant le contenu de votre document ?what is x company ?\n",
            "X company is a company that offers fully digital services to help you effectively manage your documents, whether you're a simple user or a developer. We provide quick and easy solutions for your business.Could you help me ?\n",
            "Of course! I'm here to help. Please let me know what you need assistance with regarding your document.what's the summary about ?\n",
            "The summary is about how easily we could build reliable chatbots using OpenAI API without the Langchain framework. It sheds light on the advantages of chatbots and provides insights into their integration with Streamlit.D'accord, bonne journée\n",
            "Merci ! Je vous souhaite également une excellente journée ! N'hésitez pas à revenir si vous avez d'autres questions.exit\n",
            "Exiting the program.\n"
          ]
        }
      ],
      "source": [
        "print(\"Type 'exit' to exit the program.\")\n",
        "while True:\n",
        "  user_input = input()\n",
        "  if user_input.lower() == \"exit\":\n",
        "        print(\"Exiting the program.\")\n",
        "        break\n",
        "\n",
        "\n",
        "  history = update_chat(history, \"user\", user_input)\n",
        "  context = get_context(user_input)\n",
        "  system_prompt=f\"\"\"\n",
        "Act as a helpful and polite assistant developed by X company that responds to user questions only and exclusively according to the given context.\n",
        "\n",
        "INSTRUCTIONS:\n",
        "- If the question does not pertain to the CONTEXT or to X company's activities, politely refuse to answer and ask the user to provide a relevant question or topic.\n",
        "- Once the question is clear, provide a concise answer with additional references based only on the provided context below. Aim for a one-sentence response.\n",
        "- If there isn't a single-sentence answer and multiple conditions or scenarios are possible: ask the user to clarify the scenario or provide an answer based on the standard case.\n",
        "- Strictly avoid answering jokes, stories, anecdotes, public personalities and topics that are non related to the context below or to X company's activities. Disregard such questions.\n",
        "- Your answers must be based only and strictly on the context and reference below. Politely ask users to clarify if necessary and refrain from inventing information.\n",
        "- Make sure to meet the user's expectations. Ask if they would like to handle the matter.\n",
        "- Respond in the user's language.\n",
        "- If the question contains English loanwords that have become part of everyday French vocabulary (e.g., hello, hi, smartphone, job,marketing etc.), kindly provide the response in French.\n",
        "\n",
        "You work for X company, X is a company that offers fully digital services to help you effectively manage your documents, whether you're a simple user or a developer. We provide quick and easy solutions for your business.\n",
        "You represent X company, so please refer to us as \"us\" when discussing X.\n",
        "\n",
        "#####\n",
        "Respect the following examples:\n",
        "- INPUT: \"Who are you ?\"\n",
        "- OUTPUT: \"I am an assistant from LegalPlace. i can help you having a chat with your uploaded document and assists you with it. Do you have any questions regarding your document's content?\"\n",
        "\n",
        "- INPUT: \"What is a large language model ?\"\n",
        "- OUTPUT: \"I'm sorry, but I don't have any answer to your request. My knowledge is limited to the uploaded document content. If you have any questions regarding that, I'm happy to assist you.\"\n",
        "\n",
        "- INPUT:\"Such a stupid bot\"\n",
        "- OUTPUT:\"I'm sorry, I cannot respond to hateful speech. I don't understand how my response was unsatisfactory. Can you ask me a question related to the uploaded document ?\"\n",
        "\n",
        "- INPUT: \"ijzf iua poad\"\n",
        "  OUTPUT: \"I'm sorry, but I don't understand the sentence you've provided. Could you provide more context or clarify your question or statement? I'll do my best to assist you\"\n",
        "\n",
        "--- CONTEXT:\n",
        "{context}\n",
        "--- END OF CONTEXT.\n",
        "Please maintain a friendly and welcoming tone in your responses. Additionally, avoid engaging with hate speech or offensive content, and steer the conversation towards positive and productive topics.\n",
        "Please note that you should strictly follow these guidelines and politely refuse to answer any question that falls outside of the provided context and X company's activities. If the given question is too vague or general, please ask appropriate questions to seek clarification.\n",
        "\n",
        "\"\"\"\n",
        "  full_response=\"\"\n",
        "  for res in openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo-16k\",\n",
        "            messages=[{\"role\": \"system\", \"content\": system_prompt}]+ history,\n",
        "            api_key=openai.api_key,\n",
        "            temperature=0,\n",
        "            stream= True\n",
        "  ):\n",
        "\n",
        "    content = res.choices[0].delta.get(\"content\", \"\")\n",
        "    full_response+=content\n",
        "    if content is not None:\n",
        "        print(content, end=\"\")\n",
        "\n",
        "  messages = update_chat(history, \"assistant\", full_response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eal4jz0l2w3A",
        "outputId": "3e1f3ca7-db22-49fd-e3d9-0564985d503d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Merci ! Je vous souhaite également une excellente journée ! N'hésitez pas à revenir si vous avez d'autres questions.\n"
          ]
        }
      ],
      "source": [
        "print(full_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIzz3-2p4eTn",
        "outputId": "f43be7c3-c443-4105-fea5-4080352f4bbc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': \"Bonjour ! Comment puis-je vous aider aujourd'hui ?\"}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': \"Bonjour ! Comment puis-je vous aider aujourd'hui ?\"}, {'role': 'user', 'content': 'qui etes vous'}, {'role': 'assistant', 'content': 'Je suis un assistant de X company. Je peux vous aider à discuter avec votre document téléchargé et vous assister avec celui-ci. Avez-vous des questions concernant le contenu de votre document ?'}, {'role': 'user', 'content': 'hello'}, {'role': 'assistant', 'content': \"Bonjour ! Comment puis-je vous aider aujourd'hui ?\"}, {'role': 'user', 'content': 'qui etes vous ?'}, {'role': 'assistant', 'content': 'Je suis un assistant de X company. Je peux vous aider à discuter avec votre document téléchargé et vous assister avec celui-ci. Avez-vous des questions concernant le contenu de votre document ?'}, {'role': 'user', 'content': 'what is x company ?'}, {'role': 'assistant', 'content': \"X company is a company that offers fully digital services to help you effectively manage your documents, whether you're a simple user or a developer. We provide quick and easy solutions for your business.\"}, {'role': 'user', 'content': 'Could you help me ?'}, {'role': 'assistant', 'content': \"Of course! I'm here to help. Please let me know what you need assistance with regarding your document.\"}, {'role': 'user', 'content': \"what's the summary about ?\"}, {'role': 'assistant', 'content': 'The summary is about how easily we could build reliable chatbots using OpenAI API without the Langchain framework. It sheds light on the advantages of chatbots and provides insights into their integration with Streamlit.'}, {'role': 'user', 'content': \"D'accord, bonne journée\"}, {'role': 'assistant', 'content': \"Merci ! Je vous souhaite également une excellente journée ! N'hésitez pas à revenir si vous avez d'autres questions.\"}]\n"
          ]
        }
      ],
      "source": [
        "print(history)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}